---
title: "Overfitting/Pseudoreplication"
author: "Jonathan Bakdash and Laura Marusich"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
bibliography: references.bib 
vignette: >
  %\VignetteIndexEntry{Overfitting/Pseudoreplication}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, tidy = FALSE)
options(width = 80)
library(knitr)
library(rmarkdown)
library(rmcorr) 
library(ggplot2) 
require(dplyr)
library(patchwork)
```

### Overfitting/Pseudoreplication
Switch example?
In the original rmcorr paper [@bakdash2017repeated], we noted that analyzing non-independent observations as independent will "often produce erroneous results." In this vignette, we illustrate the specific, potential consequences for this type of overfitting: **misestimated associations combined with underestimated variance leading to *p*-values that are too low**. Ignoring dependencies in data is also referred to as *pseudoreplication*, see X, Y, and Z. 

#### Example of Overfitting/Pseudoreplication
```{r, echo = FALSE}
N.Marusich2016 <- length(unique(marusich2016_exp2$Pair))
k.Marusich2016 <- length(unique(marusich2016_exp2$SourceReliablity))
total.obs.Marusich2016 <- length(marusich2016_exp2$Pair)
```

We demonstrate overfitting/pseudoreplication using [data](../reference/marusich2016_exp2.html) from [@marusich2016]. This dataset has a sample size of *N* = `r N.Marusich2016` dyads (two participants working together) with *k* = `r k.Marusich2016` paired repeated measures observations per dyad. There is a total of `r total.obs.Marusich2016` paired observations (*N* x *k*).

In the left figure, we fit a simple regression/correlation incorrectly treating the `r total.obs.Marusich2016` observations as independent. In the right figure, we demonstrate one approach to analyzing the between-participants relationship without overfitting: averaging the data by participant.

```{r}
overfit.plot <- 
    ggplot(data = marusich2016_exp2, aes(x = MARS, y = HVT_capture)) +
    geom_point(aes(colour = factor(Pair))) +
    geom_smooth(method= "lm", level = 0.95) +
    coord_cartesian(xlim = c(2,4), ylim=c(0,30)) + 
    theme(legend.position="none")

marusich2016_avg <- marusich2016_exp2 %>%
                    group_by(Pair) %>%
                    summarize(Mean_MARS = mean(MARS),
                              Mean_HVT_capture = mean(HVT_capture))

average.plot <- 
    ggplot(data = marusich2016_avg, 
           aes(x = Mean_MARS, y = Mean_HVT_capture)) +
    geom_smooth(fullrange = TRUE, method= "lm", level = 0.95) +
    coord_cartesian(xlim = c(2,4), ylim=c(0,30)) +
    geom_point(aes(colour = factor(Pair))) +
    scale_colour_discrete(name = "Pair") 

overfit.plot + average.plot

#Inferential stats
overfit.cor <- cor.test(marusich2016_exp2$MARS, marusich2016_exp2$HVT_capture)

average.cor <- cor.test(marusich2016_avg$Mean_MARS, marusich2016_avg$Mean_HVT_capture)

df.s <- rbind(overfit.cor$parameter, average.cor$paramter)

r.s  <- rbind(round(rbind(overfit.cor$estimate, average.cor$estimate), digits = 2)) 

CI.s <- formatC(rbind(overfit.cor$conf.int, 
          average.cor$conf.int), digits = 2,
          format = 'f')

p.vals <- rbind(round(overfit.cor$p.value, digits = 3), 
                prettyNum(average.cor$p.value, digits = 2, 
                          drop0trailing = TRUE))
```

The x-axis is the Mission Awareness Rating Scale (MARS), higher values indicate better situation awareness. The y-axis is task performance, the time in seconds to capture High Value Targets (HVT). Lower time values depict greater performance. The band around each regression line is a 95\% confidence interval.

The inferential statistics for these plots are:
Overfit (left): *r(`r df.s[1]`)* = `r r.s[1]` 95\% CI [`r CI.s[1,]`],  *p* = `r p.vals[1]`.

Average (right): *r(`r df.s[2]`)* = `r r.s[2]` , 95\% [`r CI.s[2,]`], *p* = `r p.vals[2]`.

For the overfit results, note the Pearson correlation `r df.s[1]` the excessive degrees of freedom imply an inflated sample size of *N* = `r df.s[1] + 2` (there are *N*-2 degrees of freedom for a correlation). This is the total number of observations, **not** the sample size.

1) Misestimated effect size: The overfit analysis has an approximately medium negative correlation, whereas the averaged analysis has slightly less than small negative correlation.  

2) Underestimated variance: The coverage of the confidence intervals (visually on the plot and in the inferential statistics) is narrower than it should be for the overfit analysis compared to the averaged data.

3) *p*-value too small: Because variance is underestimated with excessive degrees of freedom, the overfit example is highly significant. 

#### Prevalence of Overfitting/Pseudoreplication

#### Analytic Function for Underestimation of Variance

```{r, eval = FALSE}

```

##### Detecing Overfitting/Pseudoreplication
The simplest way too detect overfitting is if the degrees of freedom imply an inflated sample size, such as the above example. 

When the degrees of freedom are not reported, it *may* still be possible to detect overfitting if sufficient information is provided by reporting of other values. For example, an exact *p*-value and the known sample size *N* can be used to calculate the expected effect size and compare it to the reported effect size. See the last code chunk in this R Markdown document for an example: https://osf.io/cnfjt.