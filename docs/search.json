[{"path":"http://lmarusich.github.io/rmcorr/articles/compcor.html","id":"comparing-correlations","dir":"Articles","previous_headings":"","what":"Comparing Correlations","title":"Comparing Correlations","text":"show examples comparing magnitude two rrm values. Correlations compared using cocor package: R package Paper Web Version","code":""},{"path":"http://lmarusich.github.io/rmcorr/articles/compcor.html","id":"independent-correlations","dir":"Articles","previous_headings":"Comparing Correlations","what":"Independent Correlations","title":"Comparing Correlations","text":"first example, compare rrm values two distinct, independent datasets. , participants. nonsense example two datasets completely different experimental design share common measures.  Note two rrm values similar magnitude large overlap confidence intervals: rrm = -0.58, 95% CI [-0.74, -0.38] rrm = -0.40, 95% CI [-0.66, -0.07]. Thus, significantly different.","code":"#1) Run rmcorr on two different datasets model1.marusich2016_exp2  <- rmcorr(Pair, HVT_capture, MARS, marusich2016_exp2) #> Warning in rmcorr(Pair, HVT_capture, MARS, marusich2016_exp2): 'Pair' coerced #> into a factor model1.marusich2016_exp2 #>  #> Repeated measures correlation #>  #> r #> -0.5890471 #>  #> degrees of freedom #> 55 #>  #> p-value #> 1.434929e-06 #>  #> 95% confidence interval #> -0.738878 -0.3837139  model2.gilden2010         <- rmcorr(sub, rt, acc, gilden2010 ) #> Warning in rmcorr(sub, rt, acc, gilden2010): 'sub' coerced into a factor model2.gilden2010 #>  #> Repeated measures correlation #>  #> r #> -0.406097 #>  #> degrees of freedom #> 32 #>  #> p-value #> 0.01716871 #>  #> 95% confidence interval #> -0.6611673 -0.06687244  #2) Extract relevant parameters #Model 1 rmcorr1 <- model1.marusich2016_exp2$r rmcorr1 #> [1] -0.5890471  n1 <- model1.marusich2016_exp2$df + 2 #note the same kludge as power above n1                                    #this is the effective sample size #> [1] 57  #Model 2 rmcorr2 <- model2.gilden2010$r rmcorr2 #> [1] -0.406097  n2 <- model2.gilden2010$df + 2  n2 #> [1] 34  #3) Compare the two indendent rmcorr coefficients cocor.indep.groups(rmcorr1, rmcorr2, n1, n2,                     var.labels = c(model1.marusich2016_exp2$var[2:3],                                   model2.gilden2010$vars[2:3])) #>  #>   Results of a comparison of two correlations based on independent groups #>  #> Comparison between r1.jk (HVT_capture, MARS) = -0.589 and r2.hm (rt, acc) = -0.4061 #> Difference: r1.jk - r2.hm = -0.183 #> Data: j = HVT_capture, k = MARS, h = rt, m = acc #> Group sizes: n1 = 57, n2 = 34 #> Null hypothesis: r1.jk is equal to r2.hm #> Alternative hypothesis: r1.jk is not equal to r2.hm (two-sided) #> Alpha: 0.05 #>  #> fisher1925: Fisher's z (1925) #>   z = -1.0885, p-value = 0.2764 #>   Null hypothesis retained #>  #> zou2007: Zou's (2007) confidence interval #>   95% confidence interval for r1.jk - r2.hm: -0.5420 0.1365 #>   Null hypothesis retained (Interval includes 0)"},{"path":"http://lmarusich.github.io/rmcorr/articles/compcor.html","id":"correlated-correlations","dir":"Articles","previous_headings":"Comparing Correlations","what":"Correlated Correlations","title":"Comparing Correlations","text":"next two examples, compare rrm dataset. dependent groups – data participants.","code":""},{"path":"http://lmarusich.github.io/rmcorr/articles/compcor.html","id":"overlapping-correlations","dir":"Articles","previous_headings":"Comparing Correlations > Correlated Correlations","what":"Overlapping Correlations","title":"Comparing Correlations","text":"overlapping correlations, common variable. , compare correlations action measures distance perception. first correlation Blindwalk Away Blindwalk Toward (rrm = 0.81, 95% CI [0.75, 0.85]) second Blindwalk Toward Triangulated Blindwalk (rrm = 0.23, 95% CI [0.08, 0.36]). Note correlations significantly different 0 substantially different magnitudes wide separation confidence intervals. Hence, two correlations significantly different p < 0.0001 9 comparison tests. Also, note overlapping common variable Blindwalk Toward.","code":"variables.overlap<- c(\"Blindwalk Away\",                       \"Blindwalk Toward\",                       \"Triangulated BW\")  dist_rmc_mat_overlap <- rmcorr_mat(participant = Subject,                                     variables = variables.overlap,                                     dataset = twedt_dist_measures,                                    CI.level = 0.95)  #dist_rmc_mat_action$summary  #Use summary component  model1.bwa.bwt <- dist_rmc_mat_overlap$summary[1,]  model2.bwa.tri <- dist_rmc_mat_overlap$summary[2,] model3.bwt.tri <- dist_rmc_mat_overlap$summary[3,]  r.jk <- model1.bwa.bwt$rmcorr.r r.jh <- model2.bwa.tri$rmcorr.r #overlap r.kh <- model3.bwt.tri$rmcorr.r   #Since there is missing data, the results are unbalanced. We use the average effective sample size. n    <- mean(dist_rmc_mat_overlap$summary$effective.N)  cocor.dep.groups.overlap(r.jk,                           r.jh,                           r.kh,                           n,                           alternative = \"two.sided\",                           test = \"all\",                           var.labels = variables.overlap) #Same as variables used in rmcorr_mat() #>  #>   Results of a comparison of two overlapping correlations based on dependent groups #>  #> Comparison between r.jk (Blindwalk Away, Blindwalk Toward) = 0.8066 and r.jh (Blindwalk Away, Triangulated BW) = 0.2383 #> Difference: r.jk - r.jh = 0.5683 #> Related correlation: r.kh = 0.2255 #> Data: j = Blindwalk Away, k = Blindwalk Toward, h = Triangulated BW #> Group size: n = 177 #> Null hypothesis: r.jk is equal to r.jh #> Alternative hypothesis: r.jk is not equal to r.jh (two-sided) #> Alpha: 0.05 #>  #> pearson1898: Pearson and Filon's z (1898) #>   z = 7.8559, p-value = 0.0000 #>   Null hypothesis rejected #>  #> hotelling1940: Hotelling's t (1940) #>   t = 10.2385, df = 174, p-value = 0.0000 #>   Null hypothesis rejected #>  #> williams1959: Williams' t (1959) #>   t = 9.3823, df = 174, p-value = 0.0000 #>   Null hypothesis rejected #>  #> olkin1967: Olkin's z (1967) #>   z = 7.8559, p-value = 0.0000 #>   Null hypothesis rejected #>  #> dunn1969: Dunn and Clark's z (1969) #>   z = 8.7407, p-value = 0.0000 #>   Null hypothesis rejected #>  #> hendrickson1970: Hendrickson, Stanley, and Hills' (1970) modification of Williams' t (1959) #>   t = 10.2368, df = 174, p-value = 0.0000 #>   Null hypothesis rejected #>  #> steiger1980: Steiger's (1980) modification of Dunn and Clark's z (1969) using average correlations #>   z = 8.5460, p-value = 0.0000 #>   Null hypothesis rejected #>  #> meng1992: Meng, Rosenthal, and Rubin's z (1992) #>   z = 8.3907, p-value = 0.0000 #>   Null hypothesis rejected #>   95% confidence interval for r.jk - r.jh: 0.6700 1.0784 #>   Null hypothesis rejected (Interval does not include 0) #>  #> hittner2003: Hittner, May, and Silver's (2003) modification of Dunn and Clark's z (1969) using a backtransformed average Fisher's (1921) Z procedure #>   z = 8.3966, p-value = 0.0000 #>   Null hypothesis rejected #>  #> zou2007: Zou's (2007) confidence interval #>   95% confidence interval for r.jk - r.jh: 0.4288 0.7139 #>   Null hypothesis rejected (Interval does not include 0)"},{"path":"http://lmarusich.github.io/rmcorr/articles/compcor.html","id":"non-overlapping-correlations","dir":"Articles","previous_headings":"Comparing Correlations > Correlated Correlations","what":"Non-Overlapping Correlations","title":"Comparing Correlations","text":"non-overlapping correlations, data participants overlapping variable comparison. compare correlations two action measures distance perception (blindwalk away blindwalk toward) two direct measures (verbal visual matching). respective correlations (rrm = 0.81, 95% CI [0.75, 0.85]) (rrm = 0.73, 95% CI [0.66, 0.80]). non-overlapping correlations similar magnitude partially overlapping confidence intervals. Thus, barely significantly different p < 0.04.","code":"variables.nonoverlap  <- c(\"Blindwalk Away\",                            \"Blindwalk Toward\",                            \"Verbal\",                            \"Visual matching\")  dist_rmc_mat_nonoverlap <- rmcorr_mat(participant = Subject,                                        variables = variables.nonoverlap,                                        dataset = twedt_dist_measures,                                       CI.level = 0.95)  dist_rmc_mat_nonoverlap$summary #>           measure1         measure2  df  rmcorr.r   lowerCI   upperCI #> 1   Blindwalk Away Blindwalk Toward 175 0.8065821 0.7477023 0.8528777 #> 2   Blindwalk Away           Verbal 175 0.7355813 0.6591653 0.7969613 #> 3   Blindwalk Away  Visual matching 174 0.7758245 0.7088722 0.8289209 #> 4 Blindwalk Toward           Verbal 177 0.7160551 0.6356957 0.7810611 #> 5 Blindwalk Toward  Visual matching 177 0.7575109 0.6867423 0.8140545 #> 6           Verbal  Visual matching 179 0.7341831 0.6584114 0.7952224 #>         p.vals effective.N #> 1 8.228992e-42         177 #> 2 2.056415e-31         177 #> 3 1.226384e-36         176 #> 4 1.937983e-29         179 #> 5 1.302874e-34         179 #> 6 6.400493e-32         181  #Use summary component  model1.bwa.bwt   <- dist_rmc_mat_nonoverlap$summary[1,]  model2.verb.vis  <- dist_rmc_mat_nonoverlap$summary[6,] model3.bwa.verb  <- dist_rmc_mat_nonoverlap$summary[2,] model4.bwa.vis   <- dist_rmc_mat_nonoverlap$summary[3,]  model5.bwt.verb  <- dist_rmc_mat_nonoverlap$summary[4,]  model6.bwt.vis   <- dist_rmc_mat_nonoverlap$summary[5,]   #Cheatsheet     #j = bwa     #k = bwt     #h = verb     #m = vis  r.jk <- model1.bwa.bwt$rmcorr.r  #Action measures r.hm <- model2.verb.vis$rmcorr.r #Direct measures r.jh <- model3.bwa.verb$rmcorr.r #bwa ~ verb r.jm <- model4.bwa.vis$rmcorr.r  #bwa ~ vis r.kh <- model5.bwt.verb$rmcorr.r #bwt ~ verb r.km <- model6.bwt.vis$rmcorr.r  #bwt ~ vis  #Since there is missing data, we use the average effective sample size. n    <- round(mean(dist_rmc_mat_nonoverlap$summary$effective.N), digits = 0)  cocor.dep.groups.nonoverlap(r.jk,                             r.hm,                              r.jh,                              r.jm,                              r.kh,                              r.km,                              n,                              alternative = \"two.sided\",                              test = \"all\",                              var.labels = variables.nonoverlap) #Same as variables used in rmcorr_mat() #>  #>   Results of a comparison of two nonoverlapping correlations based on dependent groups #>  #> Comparison between r.jk (Blindwalk Away, Blindwalk Toward) = 0.8066 and r.hm (Verbal, Visual matching) = 0.7342 #> Difference: r.jk - r.hm = 0.0724 #> Related correlations: r.jh = 0.7356, r.jm = 0.7758, r.kh = 0.7161, r.km = 0.7575 #> Data: j = Blindwalk Away, k = Blindwalk Toward, h = Verbal, m = Visual matching #> Group size: n = 178 #> Null hypothesis: r.jk is equal to r.hm #> Alternative hypothesis: r.jk is not equal to r.hm (two-sided) #> Alpha: 0.05 #>  #> pearson1898: Pearson and Filon's z (1898) #>   z = 2.0556, p-value = 0.0398 #>   Null hypothesis rejected #>  #> dunn1969: Dunn and Clark's z (1969) #>   z = 2.0870, p-value = 0.0369 #>   Null hypothesis rejected #>  #> steiger1980: Steiger's (1980) modification of Dunn and Clark's z (1969) using average correlations #>   z = 2.0864, p-value = 0.0369 #>   Null hypothesis rejected #>  #> raghunathan1996: Raghunathan, Rosenthal, and Rubin's (1996) modification of Pearson and Filon's z (1898) #>   z = 2.0870, p-value = 0.0369 #>   Null hypothesis rejected #>  #> silver2004: Silver, Hittner, and May's (2004) modification of Dunn and Clark's z (1969) using a backtransformed average Fisher's (1921) Z procedure #>   z = 2.0847, p-value = 0.0371 #>   Null hypothesis rejected #>  #> zou2007: Zou's (2007) confidence interval #>   95% confidence interval for r.jk - r.hm: 0.0044 0.1460 #>   Null hypothesis rejected (Interval does not include 0)"},{"path":[]},{"path":"http://lmarusich.github.io/rmcorr/articles/FAQ_and_limitations.html","id":"how-to-calculate-power","dir":"Articles","previous_headings":"Frequently Asked Questions","what":"How to Calculate Power","title":"Frequently Asked Questions and Limitations","text":"Power can calculated using power.rmcorr function. function modifies pwr.r.test pwr package use rmcorr degrees freedom. presently included rmcorr package. Notation: N sample size, k (average) number repeated measures individual, rrm rmcorr effect size.","code":""},{"path":"http://lmarusich.github.io/rmcorr/articles/FAQ_and_limitations.html","id":"power-rmcorr-example","dir":"Articles","previous_headings":"Frequently Asked Questions > How to Calculate Power","what":"power.rmcorr Example","title":"Frequently Asked Questions and Limitations","text":"N = 100, k = 3, rrm = 0.20. design 82% power. See Power curves information. G*Power software, power can calculated substituting rmcorr degrees freedom Pearson correlation. Instead sample size, use degrees freedom rmcorr plus two (effective sample size). Pearson correlation N - 2 degrees freedom. Rmcorr exact degrees freedom = N x (k - 1) - 1 Approximate degrees freedom = (N -1) x (k - 1)","code":"install.packages(\"pwr\") require(pwr)  power.rmcorr <- function(k, N, effectsizer, sig)     {pwr.r.test(n = ((N)*(k-1))+1, r = effectsizer, sig.level = sig)}      power.rmcorr(k = 3, N = 100, effectsizer = 0.20, sig = 0.05)     #>  #>      approximate correlation power calculation (arctangh transformation)  #>  #>               n = 201 #>               r = 0.2 #>       sig.level = 0.05 #>           power = 0.8156984 #>     alternative = two.sided"},{"path":"http://lmarusich.github.io/rmcorr/articles/FAQ_and_limitations.html","id":"exact-degrees-of-freedom-example","dir":"Articles","previous_headings":"Frequently Asked Questions > How to Calculate Power","what":"Exact Degrees of Freedom Example","title":"Frequently Asked Questions and Limitations","text":"Values: N = 100, k = 3 , rrm = 0.20 ()  rmcorr df = 100 x (3 - 1) - 1 = 200 - 1 = 199  Add two (kludge): 199 + 2 = 201  Enter N = 201 effective sample size G*Power  G*Power calculate degrees freedom N - 2 = 201 - 2 = 199. Thus, using correct degrees freedom rmcorr. Note power just slighty different calculation R, uses approximation. G*Power using exact degrees freedom","code":""},{"path":"http://lmarusich.github.io/rmcorr/articles/FAQ_and_limitations.html","id":"approximate-degrees-of-freedom-example","dir":"Articles","previous_headings":"Frequently Asked Questions > How to Calculate Power","what":"Approximate Degrees of Freedom Example","title":"Frequently Asked Questions and Limitations","text":"Values: N = 100, k = 3, rrm = 0.20 (, )  approx rmcorr df = (100 - 1) x (3 - 1) = 99 x 2 = 198  Note small difference approximate vs. exact calculation: one degree freedom  Add two (kludge) G*Power, entering sample size N = 200 Note power slighty different exact formula .","code":""},{"path":"http://lmarusich.github.io/rmcorr/articles/FAQ_and_limitations.html","id":"how-to-extract-the-slope-and-its-confidence-interval","dir":"Articles","previous_headings":"Frequently Asked Questions","what":"How to Extract the Slope and its Confidence Interval","title":"Frequently Asked Questions and Limitations","text":"","code":"my.rmc <- rmcorr(participant = Subject, measure1 = PaCO2, measure2 = pH,                   dataset = bland1995) #> Warning in rmcorr(participant = Subject, measure1 = PaCO2, measure2 = pH, : #> 'Subject' coerced into a factor   # Structure of rmcorr object #str(my.rmc)   # Extract rmcorr model coefficients coef.rmc  <- my.rmc$model$coefficients coef.rmc #>  (Intercept) Participant1 Participant2 Participant3 Participant4 Participant5  #>   7.65590848  -0.72605418  -0.02144291   0.22395850   0.24550355   0.13432752  #> Participant6 Participant7     Measure1  #>   0.20037424  -0.03394863  -0.10832305   slope.rmc <- coef.rmc[length(coef.rmc)] #Last value in coefficients is the slope slope.rmc #>  Measure1  #> -0.108323   # Confidence intervals around all estimates coef.CIs <- stats::confint(my.rmc$model)  coefs.all <- cbind(coef.rmc, coef.CIs) coefs.all #>                 coef.rmc       2.5 %      97.5 % #> (Intercept)   7.65590848  7.34994594  7.96187102 #> Participant1 -0.72605418 -0.83211999 -0.61998837 #> Participant2 -0.02144291 -0.11116705  0.06828123 #> Participant3  0.22395850  0.16049969  0.28741732 #> Participant4  0.24550355  0.16448903  0.32651806 #> Participant5  0.13432752  0.05868538  0.20996967 #> Participant6  0.20037424  0.12673292  0.27401556 #> Participant7 -0.03394863 -0.17148111  0.10358385 #> Measure1     -0.10832305 -0.16883787 -0.04780822"},{"path":"http://lmarusich.github.io/rmcorr/articles/FAQ_and_limitations.html","id":"isa-error","dir":"Articles","previous_headings":"Frequently Asked Questions","what":"isa Error","title":"Frequently Asked Questions and Limitations","text":"tldr: Updating R appears resolve error. reports error running rmcorr: Stack Question error","code":"Error in isa(Participant, \"character\") : could not find function \"isa\""},{"path":"http://lmarusich.github.io/rmcorr/articles/FAQ_and_limitations.html","id":"causes-for-the-error","dir":"Articles","previous_headings":"Frequently Asked Questions > isa Error","what":"Cause(s) for the error?","title":"Frequently Asked Questions and Limitations","text":"rmcorr uses isa(). isa() base function included R. think error occurs versions R prior 3.5.0 (due change serialization?) also ran error R 4.0.4 Code test isa() works: different error isa, another possibility older package may overwritten base isa() function:","code":"isa(\"test\", \"character\") isa(5, \"numeric\") base::isa(\"test\", \"character\") base::isa(5, \"numeric\")"},{"path":"http://lmarusich.github.io/rmcorr/articles/FAQ_and_limitations.html","id":"transformations","dir":"Articles","previous_headings":"Frequently Asked Questions","what":"Transformations","title":"Frequently Asked Questions and Limitations","text":"Transformations can used make data (errors) normal. highly recommend graphing raw transformed data.  may appropriate transform one measure transform measures. “Consider transforming every variable sight” (Gelman & Hill, 2017: Data Analysis Using Regression Multilevel/Hierarchical Models, ISBN: 9780521686891, p. 548): Google Books","code":""},{"path":[]},{"path":"http://lmarusich.github.io/rmcorr/articles/FAQ_and_limitations.html","id":"change-over-time","dir":"Articles","previous_headings":"Limitations","what":"Change Over Time","title":"Frequently Asked Questions and Limitations","text":"general, rmcorr time-independent model– model change time. partial exception time measure, age raz2005 dataset.","code":""},{"path":"http://lmarusich.github.io/rmcorr/articles/FAQ_and_limitations.html","id":"non-linearity","dir":"Articles","previous_headings":"Limitations","what":"Non-Linearity","title":"Frequently Asked Questions and Limitations","text":"Rmcorr fits linear model. data non-linear, recommend using multilevel modeling instead.","code":""},{"path":"http://lmarusich.github.io/rmcorr/articles/FAQ_and_limitations.html","id":"varying-slopes-with-influential-observations-andor-unbalanced-data","dir":"Articles","previous_headings":"Limitations","what":"Varying Slopes with Influential Observations and/or Unbalanced Data","title":"Frequently Asked Questions and Limitations","text":"slopes meaningfully vary individual, recommend using multilevel modeling instead rmcorr. Random effect slopes even rmcorr influential observations /highly unbalanced data. nicely illustrated simulations Dr. Marta Karas: rmcorr may ideal","code":""},{"path":"http://lmarusich.github.io/rmcorr/articles/FAQ_and_limitations.html","id":"other-implementations-of-rmcorr","dir":"Articles","previous_headings":"","what":"Other Implementations of rmcorr","title":"Frequently Asked Questions and Limitations","text":"know three implementations rmcorr.","code":""},{"path":"http://lmarusich.github.io/rmcorr/articles/FAQ_and_limitations.html","id":"shiny-web-app-and-standalone-with-a-graphical-interface","dir":"Articles","previous_headings":"Other Implementations of rmcorr","what":"1) Shiny: Web App and Standalone with a graphical interface","title":"Frequently Asked Questions and Limitations","text":"Web App Shiny Source Code Information Running Standalone Corresponding Paper","code":""},{"path":"http://lmarusich.github.io/rmcorr/articles/FAQ_and_limitations.html","id":"python-rm_corr-in-pinguion","dir":"Articles","previous_headings":"Other Implementations of rmcorr","what":"2) Python: rm_corr in pinguion","title":"Frequently Asked Questions and Limitations","text":"rm_corr Corresponding Paper","code":""},{"path":"http://lmarusich.github.io/rmcorr/articles/FAQ_and_limitations.html","id":"stata-rmcorr","dir":"Articles","previous_headings":"Other Implementations of rmcorr","what":"3) Stata: RMCORR","title":"Frequently Asked Questions and Limitations","text":"RMCORR","code":""},{"path":"http://lmarusich.github.io/rmcorr/articles/New_rmcorr_paper_analyses_figures.html","id":"figure-1-rmcorr-and-reg-plot","dir":"Articles","previous_headings":"","what":"1. Figure 1: rmcorr and reg plot","title":"Reproduce the Results of Repeated Measures Correlation paper","text":"","code":"# echo = FALSE, warning = FALSE, results =  \"hide\", set.seed(1)  initX <- rnorm(50) newY <- NULL newX <- NULL sub <- rep(1:10, each = 5)  rsq <- .9  addx <- -2 for (i in 1:10){     addx <- addx + .25     tempData <- initX[sub == i] + addx     sdx <- sd(tempData)     sdnoise <- sdx * (sqrt((1-rsq)/rsq))     tempy <- tempData + rnorm(5,0,sdnoise) + rnorm(1,0,3)     newY <- c(newY, tempy)     newX <- c(newX,tempData) }  exampleMat <-data.frame(cbind(sub,newX,newY))  ###standard averaged regression plot submeanx <- aggregate(exampleMat$newX, by = list(exampleMat$sub), mean) submeany <- aggregate(exampleMat$newY, by = list(exampleMat$sub), mean) mypal <- colorRampPalette(RColorBrewer::brewer.pal(10,'Paired')) cols <- mypal(10)  example.rmc <- rmcorr(sub,newX,newY,exampleMat) #> Warning in rmcorr(sub, newX, newY, exampleMat): 'sub' coerced into a factor  #for graphing: get the rmcorr coefficient (rounded) and p-value (using pvals.fct) example.rmc.r <- sprintf(\"%.2f\", round(example.rmc$r, 2)) example.rmc.p <- pvals.fct(example.rmc$p)  #ditto for cor stdr <- cor.test(submeanx[,2], submeany[,2]) example.cor.r <- sprintf(\"%.2f\", round(stdr$estimate, 2)) example.cor.p <- pvals.fct(stdr$p.value)     par(mfrow = c(1, 2), mgp = c(2.5, .75, 0), mar = c(4,4,2,1), cex = 1.2)  plot(example.rmc, xlab = \"x\", ylab = \"y\",      overall = F, palette = mypal, las = 1, ylim = c(-6, 6.5)) title(\"A)\", adj = 0) #Removed for Frontiers formatting  text(1.25, -5, adj = 1, bquote(italic(r[rm])~\"=\"~ .(example.rmc.r))) text(1.25, -5.75, adj = 1, bquote(italic('p')~.(example.rmc.p)))  plot(submeanx[,2], submeany[,2], pch = 16, col = cols, las = 1,      xlab = \"x (averaged for each participant)\",      ylab = \"y (averaged for each participant)\", ylim=c(-6,6.5), xlim=c(-3, 1)) title(\"B)\", adj = 0) #  text(0.90, -5, adj = 1, bquote(italic('r')~\"=\"~ .(example.cor.r))) text(0.90, -5.75, adj = 1, bquote(italic('p')~\"=\"~.(example.cor.p)))  abline(lm(submeany[,2]~submeanx[,2]),col=\"gray50\") #(A) Rmcorr plot: rmcorr plot for a set of hypothetical data and (B) simple regression plot: the  #corresponding regression plot for the same data averaged by participant.  #dev.copy2eps(file=\"plots/Figure1_Rmcorr_vs_reg.eps\", height = 6, width = 8) #dev.copy(pdf, file=\"plots/Figure1_Rmcorr_vs_reg.pdf\", height = 6, width = 8) #dev.off()"},{"path":"http://lmarusich.github.io/rmcorr/articles/New_rmcorr_paper_analyses_figures.html","id":"figure-2-rmcorr-vs-ols-reg","dir":"Articles","previous_headings":"","what":"2. Figure 2: rmcorr vs OLS reg","title":"Reproduce the Results of Repeated Measures Correlation paper","text":"","code":"par(mfrow = c(3,3), mar = c(1,1,.5,.5), mgp = c(2.5,.75,0),      oma = c(4,4,4,0), cex = 1.1)  makeminiplot <- function(subxs, sub.slope, intercept, constant=0, xax = \"n\",                           yax = \"n\", legend = F){          mypal <- colorRampPalette(RColorBrewer::brewer.pal(10,'Paired'))     cols <- mypal(3)          # cols <- c(\"#A6CEE3\", \"#9D686D\", \"#6A3D9A\")          subys <- list(3)     for (i in 1:3){         subys[[i]] <- subxs[[i]] * sub.slope + intercept*i + constant     }          plot(subxs[[1]],subys[[1]], type = \"n\", xlim =c(0,4), ylim = c(0,10),           xlab = \"\", ylab = \"\", xaxt = xax, yaxt = yax, las = 1)          allx <- unlist(subxs)     ally <- unlist(subys)     abline(lm(ally~allx))          for (i in 1:3) {         lines(subxs[[i]],subys[[i]], type = \"o\", col = cols[i], pch = 16)     }          if (legend) legend('bottomright', legend = \"OLS\", lwd = 1.25, bty = \"n\",                        cex = 1, inset = -0.03) }  subxs <- list(3) subxs[[1]] <- seq(0,2,.25) subxs[[2]] <- seq(1,3,.25) subxs[[3]] <- seq(2,4,.25)  #ols is positive makeminiplot(subxs, -1, 4, yax = \"s\", legend = T) makeminiplot(subxs, 0, 2.75) makeminiplot(subxs, 1, 1.5)  #ols is flat makeminiplot(subxs, -1.5, 2.45, 3, yax = \"s\") makeminiplot(subxs, 0, 0, 5) makeminiplot(subxs, 1.5, -2.4, 7)  #ols is negative makeminiplot(subxs, -.75, -2, 10, yax = \"s\", xax = \"s\") makeminiplot(subxs, 0, -3.1, 10.9, xax = \"s\") makeminiplot(subxs, .9, -4.6, 12, xax = \"s\")  mtext(side = 1, outer = T, line = 1.5, \"x\", at = c(.175, .5, .85)) mtext(side = 2, outer = T, line = 1.5, \"y\", at = c(.175, .5, .85), las = 1) # mtext(side = 3, outer = T, line = .5,  #       c(\"a) rmcorr = -1\", \"b) rmcorr = 0\", \"c) rmcorr = 1\"), #       at = c(.175, .5, .85), las = 1, cex = 1.5)  #Figure 2. These notional plots illustrate the range of potential similarities and differences  #in the intra-individual association assessed by rmcorr and the inter-individual association  #assessed by ordinary least squares (OLS) regression. Rmcorr-values depend only on the  #intra-individual association between variables and will be the same across different patterns  #of inter-individual variability. (A) rrm = −1: depicts notional data with a perfect negative  #intra-individual association between variables, (B) rrm = 0: depicts data with no  #intra-individual association, and (C) rrm = 1: depicts data with a perfect positive  #intra-individual association. In each column, the relationship between subjects  #(inter-individual variability) is different, which does not change the rmcorr-values within a  #column. However, this does change the association that would be predicted by OLS regression  #(black lines) if the data were treated as IID or averaged by participant.  #dev.copy2eps(file=\"plots/Figure2_Rmcorr_vs_OLS.eps\", height = 8, width = 8) #dev.copy(pdf, file=\"plots/Figure2_Rmcorr_vs_OLS.pdf\", height = 8, width = 8) #dev.off()"},{"path":"http://lmarusich.github.io/rmcorr/articles/New_rmcorr_paper_analyses_figures.html","id":"figure-3-rmcorr-wdata-transformations","dir":"Articles","previous_headings":"","what":"3. Figure 3: rmcorr w/data transformations","title":"Reproduce the Results of Repeated Measures Correlation paper","text":"","code":"set.seed(10) initX <- rnorm(15) newY <- NULL newX <- NULL sub <- rep(1:3, each = 5) rsq <- .7 addy <- 4 addx <- -2 for (i in 1:3){     addy <- addy - 1     addx <- addx + .25          tempData <- initX[sub == i] + addx     sdx <- sd(tempData)     sdnoise <- sdx * (sqrt((1-rsq)/rsq))     tempy <- tempData + rnorm(5,0,sdnoise) + rnorm(1,addy,1)     newY <- c(newY, tempy)     newX <- c(newX,tempData) }  par(mfrow=c(1,3), mar = c(4,4,2,2), mgp = c(2.75, .75, 0), cex = 1.2)  ###original plot exampleMat <-data.frame(cbind(sub,newX,newY)) example1.rmc <- rmcorr(sub,newX,newY,exampleMat) #> Warning in rmcorr(sub, newX, newY, exampleMat): 'sub' coerced into a factor  mypal <- colorRampPalette(RColorBrewer::brewer.pal(10,'Paired'))  plot(example1.rmc, xlab = \"x\", ylab = \"\",       overall = F, palette = mypal, xlim = c(-3.5, 1), ylim = c(-2.5,2), las = 1)  example1.rmc.r <- sprintf(\"%.2f\", round(example1.rmc$r, 2)) example1.rmc.p <- pvals.fct(example1.rmc$p)  text(-3.5, 2, adj = 0, bquote(italic(r[rm])~\"=\"~ .(example1.rmc.r))) text(-3.5, 1.75, adj = 0, bquote(italic('p')~.(example1.rmc.p))) mtext(side = 2, \"y\", las = 1, line = 2.5, cex = 1.2)  ###add 1 to all x's, multiply by 2 exampleMat2 <- exampleMat exampleMat2$newX <- exampleMat2$newX * .5 + 1 example2.rmc <- rmcorr(sub, newX, newY, exampleMat2) #> Warning in rmcorr(sub, newX, newY, exampleMat2): 'sub' coerced into a factor  example2.rmc.r <- sprintf(\"%.2f\", round(example2.rmc$r, 2)) example2.rmc.p <- pvals.fct(example2.rmc$p)  plot(example2.rmc, xlab = \"x\", ylab = \"\", overall = F,      palette = mypal, xlim = c(-3.5, 1), ylim = c(-2.5,2), las = 1)  text(-3.5, 2, adj = 0, bquote(italic(r[rm])~\"=\"~ .(example2.rmc.r))) text(-3.5, 1.75, adj = 0, bquote(italic('p')~.(example2.rmc.p)))  mtext(side = 2, \"y\", las = 1, line = 2.5, cex = 1.2)  ###just add -2 to sub3's ys exampleMat3 <- exampleMat exampleMat3$newY[11:15] <- exampleMat3$newY[11:15] - 2 example3.rmc <- rmcorr(sub, newX, newY, exampleMat3) #> Warning in rmcorr(sub, newX, newY, exampleMat3): 'sub' coerced into a factor  example3.rmc.r <- sprintf(\"%.2f\", round(example3.rmc$r, 2)) example3.rmc.p <- pvals.fct(example3.rmc$p)  plot(example3.rmc, xlab = \"x\", ylab = \"\", overall = F,      palette = mypal, xlim = c(-3.5, 1), ylim = c(-2.5,2), las = 1)  text(-3.5, 2, adj = 0, bquote(italic(r[rm])~\"=\"~ .(example3.rmc.r))) text(-3.5, 1.75, adj = 0, bquote(italic('p')~.(example3.rmc.p)))  mtext(side = 2, \"y\", las = 1, line = 2.5, cex = 1.2) #Figure 3. Rmcorr-values (and corresponding p-values) do not change with linear  #transformations of the data, illustrated here with three examples: (A) original, (B) x/2 + 1, and (C) y − 1.  #dev.copy2eps(file=\"plots/Figure3_Transformations.eps\", height = 6, width = 12) #dev.copy(pdf, file=\"plots/Figure3_Transformations.pdf\", height = 6, width = 12) #dev.off()"},{"path":"http://lmarusich.github.io/rmcorr/articles/New_rmcorr_paper_analyses_figures.html","id":"power","dir":"Articles","previous_headings":"","what":"4. Figure 4: Power curves","title":"Reproduce the Results of Repeated Measures Correlation paper","text":"","code":"power.rmcorr<-function(k, N, effectsizer, sig) {     pwr.r.test(n = ((N)*(k-1))+1, r = effectsizer, sig.level = sig)      #df are specified this way because pwr.r.test assumes the input is N, so it uses N - 2 for the df }  par(mfrow=c(1,3), cex.lab=1.50, cex.axis=1.40, cex.sub=1.40, mar=c(4.5,4.5,1.75,1))  #Small effect size k<-c(3, 5, 10, 20)  nvals <- seq(6, 300) powPearsonSmall <- sapply(nvals, function (x) pwr.r.test(n=x, r=0.1)$power)  bluecolors<-c(\"#c6dbef\", \"#9ecae1\", \"#6baed6\", \"#4292c6\", \"#2171b5\", \"#084594\")   plot(nvals, seq(0,1, length.out=length(nvals)),       xlab=expression(Sample~Size~\"(\"*italic('N')*\")\"),      yaxt = \"n\", ylab = \"Power\", las = 1, col = \"white\",       xlim=c(0,300))  axis(1, at = seq(0, 300, 100)) yLabels <- seq(0, 1, 0.2) axis(2, at=yLabels, labels=sprintf(round(100*yLabels), fmt=\"%2.0f%%\"), las=1, cex.sub = 2)  for (i in 1:4)  {     powvals <- sapply(nvals, function (x) power.rmcorr(k[i], x, 0.1, 0.05)$power)     lines(nvals, powvals, lwd=2.5, col=bluecolors[i+1]) } legend(\"bottomright\", lwd=2.5, col=bluecolors, bty= 'n', legend=c(\"1\", \"3\", \"5\", \"10\", \"20\"), title = expression(italic('k')),        cex = 1.2) lines(nvals, powPearsonSmall, col=bluecolors[1], lwd= 2.5) abline(a = 0.8, b=0, col=1, lty=2, lwd= 2.5)  #Medium effect size k<-c(3, 5, 10, 20) nvals <- seq(6, 60) powPearsonMedium <- sapply(nvals, function (x) pwr.r.test(n=x, r=0.3)$power) greencolors<-c(\"#c7e9c0\",\"#a1d99b\",\"#74c476\",\"#41ab5d\",\"#238b45\",\"#005a32\")  #orangecols<-brewer.pal(9, \"Oranges\") #orangecols3<-c(orangecols[2],orangecols[3],orangecols[5],orangecols[7],orangecols[9])  plot(nvals, seq(0,1, length.out=length(nvals)),       xlab=expression(Sample~Size~\"(\"*italic('N')*\")\"),      yaxt = \"n\", ylab = \"Power\", las = 1, col = \"white\",       xlim=c(0,60))  axis(1, at = seq(0, 60, 20)) yLabels <- seq(0, 1, 0.2) axis(2, at=yLabels, main = \"Power\", labels=sprintf(round(100*yLabels), fmt=\"%2.0f%%\"), las=1)  for (i in 1:4)  {     powvals <- sapply(nvals, function (x) power.rmcorr(k[i], x, 0.3, 0.05)$power)     lines(nvals, powvals, lwd=2.5, col=greencolors[i+1]) } legend(\"bottomright\", lwd=2, col=greencolors, bty = 'n', legend=c(\"1\", \"3\", \"5\", \"10\", \"20\"), title = expression(italic('k')),        cex = 1.2) lines(nvals, powPearsonMedium, col=greencolors[1], lwd = 2.5) abline(a = 0.8, b=0, col=1, lty=2, lwd= 2.5)  #Large effect size k<-c(3, 5, 10, 20) nvals <- seq(6, 30) powPearsonlarge <- sapply(nvals, function (x) pwr.r.test(n=x, r=0.5)$power)  purplecolors<-c(\"#f2f0f7\", \"#dadaeb\", \"#bcbddc\", \"#9e9ac8\", \"#807dba\", \"#6a51a3\", \"#4a1486\")  plot(nvals, seq(0,1, length.out=length(nvals)),       xlab=expression(Sample~Size~\"(\"*italic('N')*\")\"),      yaxt = \"n\", ylab = \"Power\", las = 1, col = \"white\", xlim=c(0,30)) axis(1, at = seq(0, 40, 10)) yLabels <- seq(0, 1, 0.2) axis(2, at=yLabels, main = \"Power\", labels=sprintf(round(100*yLabels), fmt=\"%2.0f%%\"), las=1)  for (i in 1:4)  {     powvals <- sapply(nvals, function (x) power.rmcorr(k[i], x, 0.5, 0.05)$power)     lines(nvals, powvals, lwd=2.5, col=purplecolors[i+2]) } legend(\"bottomright\", lwd=2, col=purplecolors, legend=c(\"1\", \"3\", \"5\", \"10\", \"20\"), bty = 'n', title = expression(italic('k')),        cex = 1.2) abline(a = 0.8, b=0, col=1, lty=2, lwd= 2.5) lines(nvals, powPearsonlarge, col=purplecolors[2], lwd = 2.5) #Figure 4. Power curves for (A) small, rrm, and r = 0.10, (B) medium, rrm, and r = 0.3, and (C) large effect sizes, rrm,  #and r = 0.50. X-axis is sample size. Note the sample size range differs among the panels. Y-axis is power. k denotes  #the number of repeated paired measures. Eighty percent power is indicated by the dotted black line. For rmcorr, the power of  #k = 2 is asymptotically equivalent to k = 1. A comparison to the power for a Pearson correlation with one data point per  #participant (k = 1) is also shown.  #dev.copy2eps(file=\"plots/Figure4_Power_curves.eps\", height = 6, width = 6) #dev.copy(pdf, file=\"plots/Figure4_Power_curve.pdf\", height = 6, width = 6) #dev.off()"},{"path":[]},{"path":"http://lmarusich.github.io/rmcorr/articles/New_rmcorr_paper_analyses_figures.html","id":"rmcorr-and-simple-reg-results","dir":"Articles","previous_headings":"5. Brain volume and age rmcorr and simple reg/cor results and Figure 5","what":"rmcorr and simple reg results","title":"Reproduce the Results of Repeated Measures Correlation paper","text":"","code":"#Note for details on Raz: Data captured from Figure 8, Cerebellar Hemispheres (lower right) #a) Reproduce correlations in the paper: Cross-sectional (correlation at Time 1) Time1raz2005<-subset(raz2005, Time == 1) Time2raz2005<-subset(raz2005, Time == 2) a1.rtest <- cor.test(Time1raz2005$Age, Time1raz2005$Volume)  a2.rtest <- cor.test(Time2raz2005$Age, Time2raz2005$Volume)  a1.lm <- lm(Time1raz2005$Volume ~ Time1raz2005$Age) a2.lm <- lm(Time2raz2005$Volume ~ Time2raz2005$Age)  summary.a1.lm <- summary(a1.lm) summary.a2.lm <- summary(a2.lm)  a1.lm.r <- sprintf(\"%.2f\", round(a1.rtest$estimate, 2)) #Same as Pearson correlation for simple regression a1.lm.p <- pvals.fct(summary.a1.lm$coefficients[2,4])  a2.lm.r <- sprintf(\"%.2f\", round(a2.rtest$estimate ,2)) #Same as Pearson correlation for simple regression a2.lm.p <- pvals.fct(summary.a2.lm$coefficients[2,4])  #b) rmcorr analysis brainvolage.rmc <- rmcorr(participant = Participant, measure1 = Age, measure2 = Volume, dataset = raz2005) #> Warning in rmcorr(participant = Participant, measure1 = Age, measure2 = #> Volume, : 'Participant' coerced into a factor print(brainvolage.rmc) #>  #> Repeated measures correlation #>  #> r #> -0.7044077 #>  #> degrees of freedom #> 71 #>  #> p-value #> 3.561007e-12 #>  #> 95% confidence interval #> -0.8053581 -0.5637514  rmcorr.5b.r <- sprintf(\"%.2f\", round(brainvolage.rmc$r, 2)) rmcorr.5b.p <- pvals.fct(brainvolage.rmc$p)  #c) simple regression on averaged data  avgRaz2005 <- aggregate(raz2005[,3:4], by = list(raz2005$Participant), mean) avg.lm <- lm(Volume~Age, data = avgRaz2005) summary.av.lm <- summary(avg.lm) c.rtest <- cor.test(avgRaz2005$Age, avgRaz2005$Volume) print(c.rtest) #>  #>  Pearson's product-moment correlation #>  #> data:  avgRaz2005$Age and avgRaz2005$Volume #> t = -3.4912, df = 70, p-value = 0.000837 #> alternative hypothesis: true correlation is not equal to 0 #> 95 percent confidence interval: #>  -0.5662456 -0.1684542 #> sample estimates: #>        cor  #> -0.3850943  fig.5c.r <- sprintf(\"%.2f\", round(c.rtest$estimate,2)) fig.5c.p <-  pvals.fct(summary.av.lm$coefficients[2,4])  #Not graphed in Figure 5 #d) simple regression on aggregated data (incorrect overfit model): #Although in this case it doesn't matter   brainvolage.lm<-lm(Volume~Age, data = raz2005) print(brainvolage.lm) #>  #> Call: #> lm(formula = Volume ~ Age, data = raz2005) #>  #> Coefficients: #> (Intercept)          Age   #>    151.9068      -0.3399  d.rtest <- cor.test(raz2005$Age, raz2005$Volume) print(d.rtest) #>  #>  Pearson's product-moment correlation #>  #> data:  raz2005$Age and raz2005$Volume #> t = -5.165, df = 142, p-value = 7.984e-07 #> alternative hypothesis: true correlation is not equal to 0 #> 95 percent confidence interval: #>  -0.5269809 -0.2503991 #> sample estimates: #>        cor  #> -0.3976861  layout(matrix(c(1,3,4,2,3,4), 2, 3, byrow = T))  #a par(mar = c(1,4,4,2), oma = c(0,2,0,0), las = 1, cex.axis = 1.10, cex.sub = 1.10, cex.lab = 1.15) #cex.lab=1.1, cex.axis=1.1, cex.main=1.2, cex.sub=1.2) plot(Volume ~ Age, data = Time1raz2005, pch = 16,  xlab = \"\", ylab = \"\",      xlim = c(15,85), ylim = c(105,170), xaxt = \"n\") abline(a1.lm, col = \"red\", lwd = 2) axis.break(axis = 2, style = \"slash\") text(75, 170, \"Time 1\", cex = 1.5) text(18,111, adj = 0, bquote(italic('r')~\"=\"~ .(a1.lm.r))) text(18,107, adj = 0, bquote(italic('p')~.(a1.lm.p)))  title(\"A)\", adj = 0)  par(mar = c(4.5,4,1,2)) plot(Volume ~ Age, data = Time2raz2005, pch = 16, ylab = \"\",      xlim = c(15,85), ylim = c(105,170)) abline(a2.lm, col = \"red\", lwd = 2) axis.break(axis = 2, style = \"slash\") text(75, 170, \"Time 2\", cex = 1.5) text(18,111, adj = 0, bquote(italic('r')~\"=\"~ .(a2.lm.r))) text(18,107, adj = 0, bquote(italic('p')~.(a2.lm.p))) mtext(side = 2, expression(Cerebellar~Hemisphere~Volume~(cm^{3})), cex = .9,       outer = T, line = -1, las = 0)  #b par(mar = c(4.5,3,4,2)) #blueset <- brewer.pal(8, 'Blues') #pal <- colorRampPalette(blueset) pal <- colorRampPalette(kelly(n = 22))  plot(brainvolage.rmc, overall = F, palette = pal, ylab = \"\", xlab = \"Age\",       cex = 1.2, xlim = c(15,85), ylim = c(105,170))  axis.break(axis = 2, style = \"slash\") text(20,107, adj = 0, bquote(italic(r[rm])~\"=\"~ .(rmcorr.5b.r))) text(20,105, adj = 0, bquote(italic('p')~.(rmcorr.5b.p))) title(\"B)\", adj = 0)  #c plot(Volume~Age, data = avgRaz2005, ylab = \"\", xlab = \"Age\", cex = 1.2, pch = 16,       xlim = c(15,85), ylim = c(105,170)) abline(brainvolage.lm, col = \"red\", lwd = 2) axis.break(axis = 2, style = \"slash\") text(20,107, adj = 0, bquote(italic('r')~\"=\"~ .(fig.5c.r))) #incorrect positive sign in the paper text(20,105, adj = 0, bquote(italic('p')~.(fig.5c.p))) #text(20,107,paste('r =', round(c.rtest$est,2),'\\np < 0.001'), adj = 0) title(\"C)\", adj = 0) #Figure 5. Comparison of rmcorr and simple regression/correlation results for age and brain structure volume data.  #Each dot represents one of two separate observations of age and CBH for a participant. (A) #Separate simple  #regressions/correlations by time: each observation is treated as independent, represented by shading all the data  #points black. The red line is the fit of the simple regression/correlation. (B) Rmcorr: observations from the same  #participant are given the same color, with corresponding lines to show the rmcorr fit for each participant. (C)  #Simple regression/correlation: averaged by participant. Note that the effect size is greater (stronger negative  #relationship) using rmcorr (B) than with either use of simple regression models (A) and (C). This figure was  #created using data from Raz et al. (2005). #dev.copy2eps(file=\"plots/Figure5_Volume_Age.eps\", width = 9, height = 6) #dev.copy(pdf, file=\"plots/Figure5_Volume_Age.pdf\", height = 6, width = 6) #dev.off()"},{"path":[]},{"path":"http://lmarusich.github.io/rmcorr/articles/New_rmcorr_paper_analyses_figures.html","id":"rmcorr-and-simple-reg-results-1","dir":"Articles","previous_headings":"6. Visual search rmcorr and simple reg/cor results and Figure 6","what":"rmcorr and simple reg results","title":"Reproduce the Results of Repeated Measures Correlation paper","text":"","code":"#a - rmcorr vissearch.rmc <- rmcorr(participant = sub, measure1 = rt, measure2 = acc, dataset = gilden2010) #> Warning in rmcorr(participant = sub, measure1 = rt, measure2 = acc, dataset = #> gilden2010): 'sub' coerced into a factor print(vissearch.rmc) #>  #> Repeated measures correlation #>  #> r #> -0.406097 #>  #> degrees of freedom #> 32 #>  #> p-value #> 0.01716871 #>  #> 95% confidence interval #> -0.6611673 -0.06687244  #b - averaged data gildenMeans <- aggregate(gilden2010[,3:4], by = list(gilden2010$sub), mean) avg.lm <- lm(acc ~ rt, data = gildenMeans) print(avg.lm) #>  #> Call: #> lm(formula = acc ~ rt, data = gildenMeans) #>  #> Coefficients: #> (Intercept)           rt   #>      0.8132       0.1777 b.rtest <- cor.test(gildenMeans$rt, gildenMeans$acc) print(b.rtest) #>  #>  Pearson's product-moment correlation #>  #> data:  gildenMeans$rt and gildenMeans$acc #> t = 2.1966, df = 9, p-value = 0.05565 #> alternative hypothesis: true correlation is not equal to 0 #> 95 percent confidence interval: #>  -0.01409542  0.87910346 #> sample estimates: #>       cor  #> 0.5907749  #c - aggregated data (overfit, incorrectly treated as independent participants/observations) agg.lm <- lm(acc ~ rt, data = gilden2010) print(agg.lm) #>  #> Call: #> lm(formula = acc ~ rt, data = gilden2010) #>  #> Coefficients: #> (Intercept)           rt   #>      0.8612       0.1111 c.rtest <- cor.test(gilden2010$rt, gilden2010$acc) print(c.rtest) #>  #>  Pearson's product-moment correlation #>  #> data:  gilden2010$rt and gilden2010$acc #> t = 2.6401, df = 42, p-value = 0.01158 #> alternative hypothesis: true correlation is not equal to 0 #> 95 percent confidence interval: #>  0.09053513 0.60625185 #> sample estimates: #>       cor  #> 0.3772751  par(mfrow=c(1,3), mar=c(5,4.6,4,0.5), mgp=c(3.2,0.8,0),  oma = c(0, 0, 0, 0), las = 1, cex.axis = 1.2, cex.sub = 1.1, cex.lab = 1.2)  #, cex.axis = 1.10, cex.sub = 1.10, cex.lab = 1.15)  plot(vissearch.rmc, overall = F, xlab = \"Response Time (seconds)\",       ylab = \"Accuracy\", cex = 1.2,      ylim = c(.79, 1), xlim = c(0.45, .95))  axis.break(axis = 1, style = \"slash\") axis.break(axis = 2, style = \"slash\")               #example of rounding and pvals.fct inside text() text(0.95,0.8, adj = 1,    bquote(italic(r[rm])~\"=\"~.(round(vissearch.rmc$r, digits = 2))), cex = 1.2) text(0.95,0.7925, adj = 1, bquote(italic('p')~\"<\"~.(pvals.fct(vissearch.rmc$p))), cex = 1.2) title(\"A)\", adj = 0)  plot(acc~rt, data = gildenMeans, cex = 1.2, pch = 16, ylim = c(.79, 1),       xlim = c(0.45, .95), xlab = \"Response Time (seconds)\",  ylab = \"\") abline(avg.lm, col = \"red\", lwd = 2) axis.break(axis = 1, style = \"slash\") axis.break(axis = 2, style = \"slash\") text(0.95,0.8,    adj = 1, bquote(italic('r')~\"=\"~ .(round(b.rtest$estimate, digits = 2))), cex = 1.2) text(0.95,0.7925, adj = 1, bquote(italic('p')~\"=\"~.(pvals.fct(b.rtest$p.value))), cex = 1.2) #text(.95,.8,paste('r =', round(b.rtest$est,2),'\\np =', round(b.rtest$p.value,2)), adj = 1) title(\"B)\", adj = 0)  plot(acc~rt, data = gilden2010, xlab = \"Response Time (seconds)\", ylab = \"\",      cex = 1.2, pch = 16, ylim = c(.79, 1), xlim = c(0.45, .95)) abline(agg.lm, col = \"red\", lwd = 2) axis.break(axis = 1, style = \"slash\") axis.break(axis = 2, style = \"slash\") text(0.95,0.8, adj = 1, bquote(italic('r')~\"=\"~ .(round(c.rtest$estimate, digits = 2))), cex = 1.2) text(0.95,0.7925, adj = 1, bquote(italic('p')~\"<\"~.(pvals.fct(c.rtest$p.value))), cex = 1.2) title(\"C)\", adj = 0) #text(.95,.8,paste('r =', round(c.rtest$est,2),'\\np =', round(c.rtest$p.value,2)), adj = 1)  #Figure 6. The x-axis is reaction time (seconds) and the y-axis is accuracy in visual search. (A) Rmcorr: each dot represents  #the average reaction time and accuracy for a block, color identifies participant, #and colored lines show rmcorr fits for  #each participant. (B) Simple regression/correlation (averaged data): each dot represents a block, (improperly) treated as an  #independent observation. The red line is #the fit to the simple regression/correlation. (C) Simple regression/correlation  #(aggregated data): improperly treating each dot as independent. This figure was created using data from Gilden et al. (2010). #dev.copy2eps(file=\"plots/Figure6_Visual_Search.eps\", width = 9, height = 6) #dev.copy(pdf, file=\"plots/Figure6_Visual_Search.pdf\", height = 9, width = 6) #dev.off()"},{"path":"http://lmarusich.github.io/rmcorr/articles/New_rmcorr_paper_analyses_figures.html","id":"appendix-c","dir":"Articles","previous_headings":"","what":"Appendix C","title":"Reproduce the Results of Repeated Measures Correlation paper","text":"Rmcorr multilevel model Raz et al. 2005 data  Rmcorr multilevel model Gilden et al. 2010 data","code":"brainvolage.rmc <- rmcorr(participant = Participant, measure1 = Age, measure2 = Volume, dataset = raz2005)  #Null multilevel model: Random intercept and fixed slope null.vol <- lmer(Volume ~ Age + (1 | Participant), data = raz2005, REML = FALSE)  #Model fit null.vol #> Linear mixed model fit by maximum likelihood  ['lmerMod'] #> Formula: Volume ~ Age + (1 | Participant) #>    Data: raz2005 #>       AIC       BIC    logLik  deviance  df.resid  #>  977.4705  989.3497 -484.7352  969.4705       140  #> Random effects: #>  Groups      Name        Std.Dev. #>  Participant (Intercept) 11.287   #>  Residual                 3.024   #> Number of obs: 144, groups:  Participant, 72 #> Fixed Effects: #> (Intercept)          Age   #>    163.7090      -0.5533  #Parameter Confidence Intervals confint(null.vol) #> Computing profile confidence intervals ... #>                   2.5 %      97.5 % #> .sig01        9.5208850  13.6036847 #> .sigma        2.5713387   3.6236647 #> (Intercept) 155.1479333 172.3796868 #> Age          -0.7016833  -0.4056009  #Model fitted values and confidence intervals for each participant (L1 effects) set.seed(9999) L1.predict.raz <- predictInterval(null.vol, newdata = raz2005, n.sims = 1000) L1.predict.raz <- cbind(raz2005$Participant, L1.predict.raz)  theme_minimal =  theme_bw() +             theme(                   legend.position=\"none\",                   axis.line.x = element_line(color=\"black\", size = 0.9),                   axis.line.y = element_line(color=\"black\", size = 0.9),                   axis.text.x = element_text(size = 12),                   axis.text.y = element_text(size = 12),                    axis.title.x = element_text(size = 12),                   axis.title.y = element_text(size = 12)                   )   #Create custom color palette  # Blues<-brewer.pal(9,\"Blues\")  ggplot(raz2005, aes(x = Age, y = Volume, group = Participant, color = Participant)) +   geom_line(aes(y = predict(null.vol)), linetype = 2) +    geom_line(aes(y = brainvolage.rmc$model$fitted.values), linetype = 1) +    geom_ribbon(aes(ymin = L1.predict.raz$lwr,                   ymax = L1.predict.raz$upr,                   group = L1.predict.raz$`raz2005$Participant`,                   linetype = NA), alpha = 0.07) +   theme_minimal +    labs(title = \"Rmcorr and Random Intercept Multilevel Model:\\n Raz et al. 2005 Data\", x = \"Age\",         y = expression(Cerebellar~Hemisphere~Volume~(cm^{3}))) +   geom_point(aes(colour = Participant)) +   scale_colour_gradientn(colours=kelly(22)) + theme(plot.title = element_text(hjust = 0.5)) +    geom_abline(intercept = fixef(null.vol)[1], slope = fixef(null.vol)[2], colour = \"black\", size = 1, linetype = 2) #Appendix C, Figure 1: Dots are actual data values, with color indicating participant. Solid #colored lines show the rmcorr model fit. The multilevel model fit is indicated by the dashed #colored lines for Level 1 (participant) effects and the dashed black line for Level 2 (experiment) #effects. The shaded areas are 95% confidence intervals for Level 1 effects. Note the models #clearly overlap, despite the absence of confidence intervals for rmcorr.   #Converted to EPS file using Acrobat Pro b/c EPS doesn't support transparency #ggsave(file = \"plots/AppendixC_Figure1.pdf\", width = 5.70 , height = 5.73, dpi = 300) #dev.off() vissearch.rmc <- rmcorr(participant = sub, measure1 = rt, measure2 = acc, dataset = gilden2010)  null.vis <- lmer(acc ~ rt + (1 | sub), data = gilden2010, REML = FALSE)  #Model 1: Random intercept + random slope for RT model1.vis <- lmer(acc ~ rt + (1 + rt | sub), data = gilden2010, REML = FALSE) #> boundary (singular) fit: see help('isSingular')  #Model Comparison #a) Chi-Square anova(null.vis, model1.vis) #> Data: gilden2010 #> Models: #> null.vis: acc ~ rt + (1 | sub) #> model1.vis: acc ~ rt + (1 + rt | sub) #>            npar     AIC     BIC logLik deviance  Chisq Df Pr(>Chisq) #> null.vis      4 -197.41 -190.27 102.70  -205.41                      #> model1.vis    6 -193.46 -182.75 102.73  -205.46 0.0497  2     0.9754  #b) Evidence ratio using AIC Models.vis<-list() Models.vis<-c(null.vis, model1.vis)  if (requireNamespace(\"AICcmodavg\", quietly = TRUE)){   ModelTable2<-aictab(Models.vis, modnames = c(\"null\", \"Model 1\"))   ModelTable2   evidence(ModelTable2) } #>  #> Evidence ratio between models 'null' and 'Model 1': #> 13.43  #Estimating and graphing null model  #Parameter Confidence Intervals confint(null.vis) #> Computing profile confidence intervals ... #>                   2.5 %     97.5 % #> .sig01       0.02138120 0.05796124 #> .sigma       0.01294851 0.02139924 #> (Intercept)  0.91815424 1.05718722 #> rt          -0.15404840 0.02955915  #Model fitted values and confidence intervals for each participant (L1 effects) set.seed(9999) L1.predict.gilden <- predictInterval(null.vis, newdata = gilden2010, n.sims = 1000) L1.predict.gilden <- cbind(gilden2010$sub, L1.predict.gilden)   theme_minimal =  theme_bw() +             theme(                   legend.position=\"none\",                   axis.line.x = element_line(color=\"black\", size = 0.9),                   axis.line.y = element_line(color=\"black\", size = 0.9),                   axis.text.x = element_text(size = 12),                   axis.text.y = element_text(size = 12),                    axis.title.x = element_text(size = 12),                   axis.title.y = element_text(size = 12)                   )  #Create custom color palette  Colors12<-brewer.pal(12,\"Paired\")  ggplot(gilden2010, aes(x = rt, y = acc, group = sub, color = sub)) +   geom_line(aes(y = predict(null.vis)), linetype = 2) +    geom_line(aes(y = vissearch.rmc$model$fitted.values), linetype = 1) +    geom_ribbon(aes(ymin = L1.predict.gilden$lwr,                   ymax = L1.predict.gilden$upr,                   group = L1.predict.gilden$`gilden2010$sub`,                   linetype = NA),                   alpha = 0.07) +   theme_minimal + theme(plot.title = element_text(hjust = 0.5)) +    labs(title = \"Rmcorr and Random Intercept Multilevel Model:\\n Gilden et al. 2010 Data\", x = \"Response Time (Seconds)\", y = \"Accuracy\") +   geom_point(aes(colour = sub)) +   scale_colour_gradientn(colours=Colors12) +    geom_abline(intercept = fixef(null.vis)[1], slope = fixef(null.vis)[2], colour = \"black\", size = 1, linetype = 2) +   scale_y_continuous(breaks=seq(0.80, 1.0, 0.05)) +   scale_x_continuous(breaks=seq(0.50, 0.9, 0.1)) #Converted to EPS file using Acrobat Pro b/c EPS doesn't support transparency  #Appendix C, Figure 2: Dots are actual data values, with color indicating participant. Solid #colored lines show the rmcorr model fit. The multilevel model fit is indicated by the dashed #colored lines for Level 1 (participant) effects and the dashed black line for Level 2 (experiment) #effects. The shaded areas are 95% confidence intervals for Level 1 effects. Note the models #clearly overlap, despite the absence of confidence intervals for rmcorr.  #ggsave(file = \"plots/AppendixC_Figure2.pdf\", width = 6.5 , height = 6.5, dpi = 300)   #Estimating CIs: Convergence problems with model 1   confint(model1.vis) #> Computing profile confidence intervals ... #>                   2.5 %     97.5 % #> .sig01       0.02197527 0.11293808 #> .sig02      -1.00000000 1.00000000 #> .sig03       0.00000000        Inf #> .sigma       0.01303108 0.02157782 #> (Intercept)  0.91458725 1.06378202 #> rt          -0.15425292 0.03364490   warnings()      set.seed(9999)   predictInterval(model1.vis, newdata = gilden2010, n.sims = 1000) #>          fit       upr       lwr #> 1  0.8663920 0.8960908 0.8352832 #> 2  0.8683327 0.8992494 0.8385416 #> 3  0.8707389 0.8997923 0.8393785 #> 4  0.8725921 0.9043416 0.8411908 #> 5  0.9429413 0.9732029 0.9159473 #> 6  0.9432319 0.9722811 0.9162444 #> 7  0.9500212 0.9787765 0.9220920 #> 8  0.9521220 0.9792167 0.9237837 #> 9  0.9481541 0.9752953 0.9207015 #> 10 0.9557798 0.9844996 0.9267692 #> 11 0.9559257 0.9853144 0.9268080 #> 12 0.9596370 0.9887583 0.9285575 #> 13 0.9443758 0.9730895 0.9144351 #> 14 0.9430301 0.9705867 0.9121712 #> 15 0.9481910 0.9777425 0.9189827 #> 16 0.9500669 0.9785099 0.9180516 #> 17 0.9546490 0.9828561 0.9234057 #> 18 0.9511326 0.9826628 0.9211205 #> 19 0.9583308 0.9867742 0.9280774 #> 20 0.9601212 0.9901520 0.9312060 #> 21 0.9227967 0.9488316 0.8935664 #> 22 0.9244902 0.9553428 0.8959148 #> 23 0.9277636 0.9569939 0.8986043 #> 24 0.9300477 0.9599092 0.9000850 #> 25 0.9625122 0.9928161 0.9347764 #> 26 0.9680937 0.9978023 0.9390449 #> 27 0.9706817 1.0010774 0.9416283 #> 28 0.9749069 1.0033890 0.9446229 #> 29 0.9337347 0.9613853 0.9051130 #> 30 0.9427611 0.9688831 0.9133651 #> 31 0.9495472 0.9767039 0.9189270 #> 32 0.9506709 0.9813415 0.9226078 #> 33 0.9092402 0.9374052 0.8801574 #> 34 0.9081569 0.9380428 0.8783812 #> 35 0.9101271 0.9393227 0.8784178 #> 36 0.9130451 0.9411345 0.8840515 #> 37 0.9530667 0.9841683 0.9233226 #> 38 0.9633384 0.9921144 0.9363187 #> 39 0.9616431 0.9909585 0.9335434 #> 40 0.9655959 0.9935503 0.9362402 #> 41 0.9739775 1.0029519 0.9440092 #> 42 0.9725509 1.0019449 0.9447089 #> 43 0.9767107 1.0060772 0.9455765 #> 44 0.9756523 1.0049782 0.9452859   warnings()"},{"path":"http://lmarusich.github.io/rmcorr/articles/New_rmcorr_paper_analyses_figures.html","id":"diagnostic-plot-rmcorr-and-straight-lines-between-points-not-in-paper","dir":"Articles","previous_headings":"Appendix C","what":"Diagnostic Plot: Rmcorr and straight lines between points (not in paper)","title":"Reproduce the Results of Repeated Measures Correlation paper","text":"","code":"brainvolage.rmc <- rmcorr(participant = Participant, measure1 = Age, measure2 = Volume, dataset = raz2005) #> Warning in rmcorr(participant = Participant, measure1 = Age, measure2 = #> Volume, : 'Participant' coerced into a factor print(brainvolage.rmc) #>  #> Repeated measures correlation #>  #> r #> -0.7044077 #>  #> degrees of freedom #> 71 #>  #> p-value #> 3.561007e-12 #>  #> 95% confidence interval #> -0.8053581 -0.5637514  theme_minimal =  theme_bw() +             theme(                   legend.position=\"none\",                   axis.line.x = element_line(color=\"black\", size = 0.9),                   axis.line.y = element_line(color=\"black\", size = 0.9),                   axis.text.x = element_text(size = 12),                   axis.text.y = element_text(size = 12),                    axis.title.x = element_text(size = 12),                   axis.title.y = element_text(size = 12)                   )  ggplot(raz2005, aes(x = Age, y = Volume, group = Participant, color = Participant)) +   geom_line(aes(y = brainvolage.rmc$model$fitted.values), linetype = 1) +    theme_minimal +    labs(title = \"Rmcorr and Diagnostic Lines:\\n Raz et al. 2005 Data\", x = \"Age\",         y = expression(Cerebellar~Hemisphere~Volume~(cm^{3}))) +   geom_point(aes(colour = Participant)) +   scale_colour_gradientn(colours=kelly(22)) + theme(plot.title = element_text(hjust = 0.5)) + geom_line(linetype = 3) #ggsave(file = \"plots/Figure_rmcorr_diagnostic.pdf\", width = 5.70 , height = 5.73, dpi = 300) #ggsave(file = \"plots/Figure_rmcorr_diagnostic.eps\", width = 5.70 , height = 5.73, dpi = 300) #dev.off()"},{"path":"http://lmarusich.github.io/rmcorr/articles/rmcorr_mat.html","id":"plotting-a-correlation-matrix","dir":"Articles","previous_headings":"","what":"Plotting a Correlation Matrix","title":"Plotting and Multiple Comparisons with rmcorr_mat","text":"output rmcorr_mat can used used plot correlation matrix.","code":"dist_rmc_mat <- rmcorr_mat(participant = Subject,                             variables = c(\"Blindwalk Away\",                                          \"Blindwalk Toward\",                                          \"Triangulated BW\",                                          \"Verbal\",                                          \"Visual matching\"),                            dataset = twedt_dist_measures,                            CI.level = 0.95)  corrplot(dist_rmc_mat$matrix)"},{"path":"http://lmarusich.github.io/rmcorr/articles/rmcorr_mat.html","id":"plotting-multiple-models","dir":"Articles","previous_headings":"","what":"Plotting Multiple Models","title":"Plotting and Multiple Comparisons with rmcorr_mat","text":"output can also used plot multiple models side--side.","code":"#Number of models being plotted n.models <- length(dist_rmc_mat$models)  #Change graphing parameters to plot side-by-side #with narrower margins par(mfrow = c(3,4),      mar = c(2.75, 2.4, 2.4, 1.4))  for (i in 1:n.models) {     plot(dist_rmc_mat$models[[i]])     }  #Reset graphing parameters #dev.off()"},{"path":"http://lmarusich.github.io/rmcorr/articles/rmcorr_mat.html","id":"adjusting-for-multiple-comparisons","dir":"Articles","previous_headings":"","what":"Adjusting for Multiple Comparisons","title":"Plotting and Multiple Comparisons with rmcorr_mat","text":"third component output rmcorr_mat() contains summary results. Using summary component, demonstrate adjusting multiple comparisons using two methods: Bonferroni correction False Discovery Rate (FDR).  example also compares unadjusted p-values adjustment methods. unadjusted p-values quite small, many adjusted p-values tend similar unadjusted ones two adjustment methods also tend produce similar p-values.","code":"#Third component: Summary dist_rmc_mat$summary #>            measure1         measure2  df  rmcorr.r    lowerCI   upperCI #> 1    Blindwalk Away Blindwalk Toward 175 0.8065821 0.74770226 0.8528777 #> 2    Blindwalk Away  Triangulated BW 174 0.2382857 0.09280577 0.3738042 #> 3    Blindwalk Away           Verbal 175 0.7355813 0.65916526 0.7969613 #> 4    Blindwalk Away  Visual matching 174 0.7758245 0.70887224 0.8289209 #> 5  Blindwalk Toward  Triangulated BW 176 0.2254866 0.08024293 0.3613540 #> 6  Blindwalk Toward           Verbal 177 0.7160551 0.63569573 0.7810611 #> 7  Blindwalk Toward  Visual matching 177 0.7575109 0.68674230 0.8140545 #> 8   Triangulated BW           Verbal 178 0.1835838 0.03751202 0.3219744 #> 9   Triangulated BW  Visual matching 177 0.2537431 0.11037346 0.3867680 #> 10           Verbal  Visual matching 179 0.7341831 0.65841140 0.7952224 #>          p.vals effective.N #> 1  8.228992e-42         177 #> 2  1.449081e-03         176 #> 3  2.056415e-31         177 #> 4  1.226384e-36         176 #> 5  2.476132e-03         178 #> 6  1.937983e-29         179 #> 7  1.302874e-34         179 #> 8  1.362964e-02         180 #> 9  6.095365e-04         179 #> 10 6.400493e-32         181  #p-values only dist_rmc_mat$summary$p.vals #>  [1] 8.228992e-42 1.449081e-03 2.056415e-31 1.226384e-36 2.476132e-03 #>  [6] 1.937983e-29 1.302874e-34 1.362964e-02 6.095365e-04 6.400493e-32  #Vector of original, unadjusted p-values for all 10 comparisons p.vals <- dist_rmc_mat$summary$p.vals  p.vals.bonferroni <- p.adjust(p.vals,                                method = \"bonferroni\",                               n = length(p.vals))  p.vals.fdr <- p.adjust(p.vals,                         method = \"fdr\",                        n = length(p.vals))  #All p-values together all.pvals <- cbind(p.vals, p.vals.bonferroni, p.vals.fdr) colnames(all.pvals) <- c(\"Unadjusted\", \"Bonferroni\", \"fdr\") round(all.pvals, digits = 5) #>       Unadjusted Bonferroni     fdr #>  [1,]    0.00000    0.00000 0.00000 #>  [2,]    0.00145    0.01449 0.00181 #>  [3,]    0.00000    0.00000 0.00000 #>  [4,]    0.00000    0.00000 0.00000 #>  [5,]    0.00248    0.02476 0.00275 #>  [6,]    0.00000    0.00000 0.00000 #>  [7,]    0.00000    0.00000 0.00000 #>  [8,]    0.01363    0.13630 0.01363 #>  [9,]    0.00061    0.00610 0.00087 #> [10,]    0.00000    0.00000 0.00000"},{"path":"http://lmarusich.github.io/rmcorr/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Jonathan Z. Bakdash. Author. Laura R. Marusich. Author, maintainer.","code":""},{"path":"http://lmarusich.github.io/rmcorr/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Bakdash J, Marusich L (2022). rmcorr: Repeated Measures Correlation. https://github.com/lmarusich/rmcorr, https://lmarusich.github.io/rmcorr/.","code":"@Manual{,   title = {rmcorr: Repeated Measures Correlation},   author = {Jonathan Z. Bakdash and Laura R. Marusich},   year = {2022},   note = {https://github.com/lmarusich/rmcorr, https://lmarusich.github.io/rmcorr/}, }"},{"path":"http://lmarusich.github.io/rmcorr/index.html","id":"rmcorr-","dir":"","previous_headings":"","what":"Repeated Measures Correlation","title":"Repeated Measures Correlation","text":"Repeated measures correlation (rmcorr) statistical technique determining common within-individual association paired measures assessed two occasions multiple individuals.","code":""},{"path":"http://lmarusich.github.io/rmcorr/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Repeated Measures Correlation","text":"","code":"install.packages('rmcorr')  #development version: # install.packages(\"devtools\") devtools::install_github(\"lmarusich/rmcorr\")"},{"path":"http://lmarusich.github.io/rmcorr/index.html","id":"example","dir":"","previous_headings":"","what":"Example","title":"Repeated Measures Correlation","text":"","code":"library(rmcorr) rmcorr(Subject, PaCO2, pH, bland1995) #> Warning in rmcorr(Subject, PaCO2, pH, bland1995): 'Subject' coerced into a #> factor #>  #> Repeated measures correlation #>  #> r #> -0.5067697 #>  #> degrees of freedom #> 38 #>  #> p-value #> 0.0008471081 #>  #> 95% confidence interval #> -0.7112297 -0.223255"},{"path":"http://lmarusich.github.io/rmcorr/index.html","id":"graphical-interface-for-rmcorr","dir":"","previous_headings":"","what":"Graphical Interface for rmcorr","title":"Repeated Measures Correlation","text":"Shiny web standalone app graphical user interface also available: Web app Standalone app","code":""},{"path":"http://lmarusich.github.io/rmcorr/reference/bland1995.html","id":null,"dir":"Reference","previous_headings":"","what":"Repeated measurements of intramural pH and PaCO2 — bland1995","title":"Repeated measurements of intramural pH and PaCO2 — bland1995","text":"dataset containing repeated measurements intramural pH PaCO2 eight subjects, Bland & Altman (1995).","code":""},{"path":"http://lmarusich.github.io/rmcorr/reference/bland1995.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Repeated measurements of intramural pH and PaCO2 — bland1995","text":"","code":"bland1995"},{"path":"http://lmarusich.github.io/rmcorr/reference/bland1995.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Repeated measurements of intramural pH and PaCO2 — bland1995","text":"data frame 47 rows 3 variables","code":""},{"path":"http://lmarusich.github.io/rmcorr/reference/bland1995.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Repeated measurements of intramural pH and PaCO2 — bland1995","text":"Bland, J.M., & Altman, D.G. (1995). Calculating correlation coefficients repeated observations: Part 1 - correlation within subjects. BMJ, 310, 446,  doi: 10.1136/bmj.310.6977.446","code":""},{"path":"http://lmarusich.github.io/rmcorr/reference/gilden2010.html","id":null,"dir":"Reference","previous_headings":"","what":"Repeated measurements of reaction time and accuracy — gilden2010","title":"Repeated measurements of reaction time and accuracy — gilden2010","text":"dataset containing four repeated measurements reaction time (RT) accuracy eleven subjects visual search experiment. measurement mean RT accuracy block 288 search trials. blocks visual search, eleven subjects.","code":""},{"path":"http://lmarusich.github.io/rmcorr/reference/gilden2010.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Repeated measurements of reaction time and accuracy — gilden2010","text":"","code":"gilden2010"},{"path":"http://lmarusich.github.io/rmcorr/reference/gilden2010.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Repeated measurements of reaction time and accuracy — gilden2010","text":"data frame 44 rows 4 variables","code":""},{"path":"http://lmarusich.github.io/rmcorr/reference/gilden2010.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Repeated measurements of reaction time and accuracy — gilden2010","text":"Gilden, D.L., Thornton, T.L., & Marusich, L.R. (2010). serial process visual search. Journal Experimental Psychology: Human Perception Performance, 36, 533-542,  doi: 10.1037/a0016464","code":""},{"path":"http://lmarusich.github.io/rmcorr/reference/marusich2016_exp2.html","id":null,"dir":"Reference","previous_headings":"","what":"Repeated measurements of dyads performance and subjective situation \r\nawareness — marusich2016_exp2","title":"Repeated measurements of dyads performance and subjective situation \r\nawareness — marusich2016_exp2","text":"dataset containing three repeated measures dyads (paired   participants) working together capture High Value Targets (lower task time  better performance) averaged Mission Awareness Rating Scale  (MARS) score block, repeated three times. MARS evaluates subjective  situation awareness (”knowing going ”), higher values indicate  better situation awareness.","code":""},{"path":"http://lmarusich.github.io/rmcorr/reference/marusich2016_exp2.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Repeated measurements of dyads performance and subjective situation \r\nawareness — marusich2016_exp2","text":"","code":"marusich2016_exp2"},{"path":"http://lmarusich.github.io/rmcorr/reference/marusich2016_exp2.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Repeated measurements of dyads performance and subjective situation \r\nawareness — marusich2016_exp2","text":"data frame 84 rows (28 dyads/pairs) 4 variables","code":""},{"path":"http://lmarusich.github.io/rmcorr/reference/marusich2016_exp2.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Repeated measurements of dyads performance and subjective situation \r\nawareness — marusich2016_exp2","text":"Marusich et al. (2016). Effects information availability  command--control decision making: performance, trust, situation  awareness. Human Factors, 58(2), 301-321,  doi: 10.1177/0018720815619515","code":""},{"path":"http://lmarusich.github.io/rmcorr/reference/plot.rmc.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot the repeated measures correlation coefficient. — plot.rmc","title":"Plot the repeated measures correlation coefficient. — plot.rmc","text":"plot.rmc  produces scatterplot measure1 x-axis measure2 y-axis, different color used subject. Parallel lines fitted subject's data.","code":""},{"path":"http://lmarusich.github.io/rmcorr/reference/plot.rmc.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot the repeated measures correlation coefficient. — plot.rmc","text":"","code":"# S3 method for rmc plot(   x,   dataset = NULL,   overall = F,   palette = NULL,   xlab = NULL,   ylab = NULL,   overall.col = \"gray60\",   overall.lwd = 3,   overall.lty = 2,   ... )"},{"path":"http://lmarusich.github.io/rmcorr/reference/plot.rmc.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot the repeated measures correlation coefficient. — plot.rmc","text":"x object class \"rmc\" generated rmcorr function. dataset Deprecated: argument longer required overall logical: TRUE, plots regression line measure1 measure2, ignoring participant variable. palette palette used. Defaults RColorBrewer \"Paired\" palette xlab label x axis, defaults variable name measure1. ylab label y axis, defaults variable name measure2. overall.col color overall regression line overall.lwd line thickness overall regression line overall.lty line type overall regression line ... additional arguments plot.","code":""},{"path":[]},{"path":"http://lmarusich.github.io/rmcorr/reference/plot.rmc.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot the repeated measures correlation coefficient. — plot.rmc","text":"","code":"## Bland Altman 1995 data my.rmc <- rmcorr(participant = Subject, measure1 = PaCO2, measure2 = pH,                   dataset = bland1995) #> Warning: 'Subject' coerced into a factor plot(my.rmc)   #using ggplot instead if (requireNamespace(\"ggplot2\", quietly = TRUE)){  ggplot2::ggplot(bland1995, ggplot2::aes(x = PaCO2, y = pH,                   group = factor(Subject), color = factor(Subject))) +       ggplot2::geom_point(ggplot2::aes(colour = factor(Subject))) +       ggplot2::geom_line(ggplot2::aes(y = my.rmc$model$fitted.values),                           linetype = 1) }    ## Raz et al. 2005 data my.rmc <- rmcorr(participant = Participant, measure1 = Age, measure2 =                   Volume, dataset = raz2005) #> Warning: 'Participant' coerced into a factor library(RColorBrewer) #> Warning: package 'RColorBrewer' was built under R version 4.1.3 blueset <- brewer.pal(8, 'Blues') pal <- colorRampPalette(blueset) plot(my.rmc, overall = TRUE, palette = pal, overall.col = 'black')    ## Gilden et al. 2010 data my.rmc <- rmcorr(participant = sub, measure1 = rt, measure2 = acc,                   dataset = gilden2010) #> Warning: 'sub' coerced into a factor plot(my.rmc, overall = FALSE, lty = 2, xlab = \"Reaction Time\",       ylab = \"Accuracy\")"},{"path":"http://lmarusich.github.io/rmcorr/reference/print.rmc.html","id":null,"dir":"Reference","previous_headings":"","what":"Print the results of a repeated measures correlation — print.rmc","title":"Print the results of a repeated measures correlation — print.rmc","text":"Print results repeated measures correlation","code":""},{"path":"http://lmarusich.github.io/rmcorr/reference/print.rmc.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print the results of a repeated measures correlation — print.rmc","text":"","code":"# S3 method for rmc print(x, ...)"},{"path":"http://lmarusich.github.io/rmcorr/reference/print.rmc.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print the results of a repeated measures correlation — print.rmc","text":"x object class \"rmc\", result call rmcorr. ... additional arguments print.","code":""},{"path":[]},{"path":"http://lmarusich.github.io/rmcorr/reference/print.rmc.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Print the results of a repeated measures correlation — print.rmc","text":"","code":"## Bland Altman 1995 data blandrmc <- rmcorr(Subject, PaCO2, pH, bland1995) #> Warning: 'Subject' coerced into a factor blandrmc #>  #> Repeated measures correlation #>  #> r #> -0.5067697 #>  #> degrees of freedom #> 38 #>  #> p-value #> 0.0008471081 #>  #> 95% confidence interval #> -0.7112297 -0.223255  #>"},{"path":"http://lmarusich.github.io/rmcorr/reference/print.rmcmat.html","id":null,"dir":"Reference","previous_headings":"","what":"Print the repeated measures correlation matrix — print.rmcmat","title":"Print the repeated measures correlation matrix — print.rmcmat","text":"Print repeated measures correlation matrix","code":""},{"path":"http://lmarusich.github.io/rmcorr/reference/print.rmcmat.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print the repeated measures correlation matrix — print.rmcmat","text":"","code":"# S3 method for rmcmat print(x, ...)"},{"path":"http://lmarusich.github.io/rmcorr/reference/print.rmcmat.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print the repeated measures correlation matrix — print.rmcmat","text":"x object class \"rmcmat\", result call rmcorr_mat. ... additional arguments print.","code":""},{"path":[]},{"path":"http://lmarusich.github.io/rmcorr/reference/print.rmcmat.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Print the repeated measures correlation matrix — print.rmcmat","text":"","code":"## Bland Altman 1995 data blandrmc <- rmcorr(Subject, PaCO2, pH, bland1995) #> Warning: 'Subject' coerced into a factor blandrmc #>  #> Repeated measures correlation #>  #> r #> -0.5067697 #>  #> degrees of freedom #> 38 #>  #> p-value #> 0.0008471081 #>  #> 95% confidence interval #> -0.7112297 -0.223255  #>"},{"path":"http://lmarusich.github.io/rmcorr/reference/raz2005.html","id":null,"dir":"Reference","previous_headings":"","what":"Repeated measurements of age and cerebellar volume — raz2005","title":"Repeated measurements of age and cerebellar volume — raz2005","text":"dataset containing two repeated measures, two occasions (Time), age adjusted volume cerebellar hemispheres 72 participants. Data captured Figure 8, Cerebellar Hemispheres (lower right) Raz et al. (2005).","code":""},{"path":"http://lmarusich.github.io/rmcorr/reference/raz2005.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Repeated measurements of age and cerebellar volume — raz2005","text":"","code":"raz2005"},{"path":"http://lmarusich.github.io/rmcorr/reference/raz2005.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Repeated measurements of age and cerebellar volume — raz2005","text":"data frame 144 rows 4 variables","code":""},{"path":"http://lmarusich.github.io/rmcorr/reference/raz2005.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Repeated measurements of age and cerebellar volume — raz2005","text":"Raz, N., Lindenberger, U., Rodrigue, K.M., Kennedy, K.M., Head, D., Williamson, ., Dahle, C., Gerstorf, D., & Acker, J.D. (2005). Regional brain changes aging healthy adults: General trends, individual differences, modifiers. Cerebral Cortex, 15, 1676-1689,  doi: 10.1093/cercor/bhi044","code":""},{"path":"http://lmarusich.github.io/rmcorr/reference/rmcorr-package.html","id":null,"dir":"Reference","previous_headings":"","what":"A package for computing the repeated measures correlation coefficient — rmcorr-package","title":"A package for computing the repeated measures correlation coefficient — rmcorr-package","text":"Compute repeated measures correlation, statistical technique     determining overall within-individual relationship among paired measures     assessed two occasions, first introduced Bland Altman (1995).     Includes functions diagnostics, p-value, effect size confidence     interval including optional bootstrapping, well graphing. Also includes     several example datasets. details, see web documentation      <https://lmarusich.github.io/rmcorr/index.html>      original paper: Bakdash Marusich (2017) <doi:10.3389/fpsyg.2017.00456>.","code":""},{"path":"http://lmarusich.github.io/rmcorr/reference/rmcorr-package.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"A package for computing the repeated measures correlation coefficient — rmcorr-package","text":"Bakdash, J.Z. & Marusich, L.R. (2017).  Repeated Measures Correlation, Frontiers Psychology, 8, 256,  doi: 10.3389/fpsyg.2017.00456 Bakdash, J.Z. & Marusich, L.R. (2019).  Corrigendum: Repeated Measures Correlation, Frontiers Psychology,  doi: 10.3389/fpsyg.2019.01201","code":""},{"path":"http://lmarusich.github.io/rmcorr/reference/rmcorr.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate the repeated measures correlation coefficient. — rmcorr","title":"Calculate the repeated measures correlation coefficient. — rmcorr","text":"Calculate repeated measures correlation coefficient.","code":""},{"path":"http://lmarusich.github.io/rmcorr/reference/rmcorr.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate the repeated measures correlation coefficient. — rmcorr","text":"","code":"rmcorr(   participant,   measure1,   measure2,   dataset,   CI.level = 0.95,   CIs = c(\"analytic\", \"bootstrap\"),   nreps = 100,   bstrap.out = F )"},{"path":"http://lmarusich.github.io/rmcorr/reference/rmcorr.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate the repeated measures correlation coefficient. — rmcorr","text":"participant variable giving subject name/id observation. measure1 numeric variable giving observations one measure. measure2 numeric variable giving observations second measure. dataset data frame containing variables. CI.level confidence level interval CIs method calculating confidence intervals. nreps number resamples take bootstrapping. bstrap.Determines output include bootstrap resamples.","code":""},{"path":"http://lmarusich.github.io/rmcorr/reference/rmcorr.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate the repeated measures correlation coefficient. — rmcorr","text":"list class \"rmc\" containing following components. r value repeated measures correlation coefficient. df degrees freedom p p-value repeated measures correlation coefficient. CI 95% confidence interval repeated measures correlation coefficient. model multiple regression model used calculate correlation coefficient. resamples bootstrap resampled correlation values.","code":""},{"path":"http://lmarusich.github.io/rmcorr/reference/rmcorr.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Calculate the repeated measures correlation coefficient. — rmcorr","text":"Bakdash, J.Z., & Marusich, L.R. (2017).  Repeated Measures Correlation. Frontiers Psychology, 8, 256.  doi: 10.3389/fpsyg.2017.00456 . Bland, J.M., & Altman, D.G. (1995). Calculating correlation  coefficients repeated observations: Part 1 - correlation within subjects. BMJ, 310, 446.","code":""},{"path":[]},{"path":"http://lmarusich.github.io/rmcorr/reference/rmcorr.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate the repeated measures correlation coefficient. — rmcorr","text":"","code":"## Bland Altman 1995 data rmcorr(Subject, PaCO2, pH, bland1995) #> Warning: 'Subject' coerced into a factor #>  #> Repeated measures correlation #>  #> r #> -0.5067697 #>  #> degrees of freedom #> 38 #>  #> p-value #> 0.0008471081 #>  #> 95% confidence interval #> -0.7112297 -0.223255  #>"},{"path":"http://lmarusich.github.io/rmcorr/reference/rmcorr_mat.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a repeated measures correlation matrix. — rmcorr_mat","title":"Create a repeated measures correlation matrix. — rmcorr_mat","text":"Create repeated measures correlation matrix.","code":""},{"path":"http://lmarusich.github.io/rmcorr/reference/rmcorr_mat.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a repeated measures correlation matrix. — rmcorr_mat","text":"","code":"rmcorr_mat(participant, variables, dataset, CI.level = 0.95)"},{"path":"http://lmarusich.github.io/rmcorr/reference/rmcorr_mat.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a repeated measures correlation matrix. — rmcorr_mat","text":"participant variable giving subject name/id observation. variables character vector indicating columns variables include correlation matrix. dataset data frame containing variables. CI.level level confidence intervals use rmcorr models.","code":""},{"path":"http://lmarusich.github.io/rmcorr/reference/rmcorr_mat.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create a repeated measures correlation matrix. — rmcorr_mat","text":"list class \"rmcmat\" containing following components. matrix repeated measures correlation matrix summary dataframe showing rmcorr stats pair variables models list full rmcorr model pair variables","code":""},{"path":"http://lmarusich.github.io/rmcorr/reference/rmcorr_mat.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Create a repeated measures correlation matrix. — rmcorr_mat","text":"Bakdash, J.Z., & Marusich, L.R. (2017).  Repeated Measures Correlation. Frontiers Psychology, 8, 256.  doi: 10.3389/fpsyg.2017.00456 . Bland, J.M., & Altman, D.G. (1995). Calculating correlation  coefficients repeated observations: Part 1 - correlation within subjects. BMJ, 310, 446, doi: 10.1136/bmj.310.6977.446 .","code":""},{"path":[]},{"path":"http://lmarusich.github.io/rmcorr/reference/rmcorr_mat.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create a repeated measures correlation matrix. — rmcorr_mat","text":"","code":"dist_rmc_mat <- rmcorr_mat(participant = Subject,                             variables = c(\"Blindwalk Away\",                                          \"Blindwalk Toward\",                                          \"Triangulated BW\",                                          \"Verbal\",                                          \"Visual matching\"),                            dataset = twedt_dist_measures,                            CI.level = 0.95) plot(dist_rmc_mat$models[[2]])"},{"path":"http://lmarusich.github.io/rmcorr/reference/twedt_dist_measures.html","id":null,"dir":"Reference","previous_headings":"","what":"Repeated measures and multivariate measures of perceived distance — twedt_dist_measures","title":"Repeated measures and multivariate measures of perceived distance — twedt_dist_measures","text":"dataset repeated measures distance perception  physical distances 7, 8, 9, 10, 11 meters. data also multivariate, five dependent measures distance perception. 5 (physical distance) x 5 (dependent measure) within-participants design sample size 46. Note data missing 15 trials due participant experimenter errors.","code":""},{"path":"http://lmarusich.github.io/rmcorr/reference/twedt_dist_measures.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Repeated measures and multivariate measures of perceived distance — twedt_dist_measures","text":"","code":"twedt_dist_measures"},{"path":"http://lmarusich.github.io/rmcorr/reference/twedt_dist_measures.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Repeated measures and multivariate measures of perceived distance — twedt_dist_measures","text":"data frame 230 rows 7 columns","code":""},{"path":"http://lmarusich.github.io/rmcorr/reference/twedt_dist_measures.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Repeated measures and multivariate measures of perceived distance — twedt_dist_measures","text":"Twedt, E. Bakdash, J.Z., Proffitt, D.R. (2022). Repeated multivariate measures perceived distance (Dataset) doi: 10.5281/zenodo.6967162","code":""},{"path":"http://lmarusich.github.io/rmcorr/news/index.html","id":"rmcorr-051-dev-release-only-not-on-cran","dir":"Changelog","previous_headings":"","what":"rmcorr 0.5.1 (dev release only, not on CRAN)","title":"rmcorr 0.5.1 (dev release only, not on CRAN)","text":"Documentation update: Table describing twedt_dist_measures now markdown chunk. renders correctly pkgdown","code":""},{"path":"http://lmarusich.github.io/rmcorr/news/index.html","id":"rmcorr-050","dir":"Changelog","previous_headings":"","what":"rmcorr 0.5.0","title":"rmcorr 0.5.0","text":"CRAN release: 2022-08-08 Beta: Added rmcorr_mat() calculate rmcorr correlation matrix demonstrate rmcorr_mat(), added new dataset description: twedt_dist_measures Rewrote variable names saved rmcorr() Updated description: Minimum version R >3.5.0 serialized objects","code":""},{"path":"http://lmarusich.github.io/rmcorr/news/index.html","id":"rmcorr-047-dev-release-only-not-on-cran","dir":"Changelog","previous_headings":"","what":"rmcorr 0.4.7 (dev release only, not on CRAN)","title":"rmcorr 0.4.7 (dev release only, not on CRAN)","text":"Fixed typo bland1995 example data: PacO2 now PaCO2 (partial pressure CO2) Add marusich2016 data description Documentation: Add details bland1995 data add DOIs data references","code":""},{"path":"http://lmarusich.github.io/rmcorr/news/index.html","id":"rmcorr-046","dir":"Changelog","previous_headings":"","what":"rmcorr 0.4.6","title":"rmcorr 0.4.6","text":"CRAN release: 2022-05-02 use packages ‘suggests’ conditionally","code":""},{"path":"http://lmarusich.github.io/rmcorr/news/index.html","id":"rmcorr-045","dir":"Changelog","previous_headings":"","what":"rmcorr 0.4.5","title":"rmcorr 0.4.5","text":"CRAN release: 2021-12-01 Fix issue column names Add testing","code":""},{"path":"http://lmarusich.github.io/rmcorr/news/index.html","id":"rmcorr-044","dir":"Changelog","previous_headings":"","what":"rmcorr 0.4.4","title":"rmcorr 0.4.4","text":"CRAN release: 2021-08-10 Just changing maintainer email address","code":""},{"path":"http://lmarusich.github.io/rmcorr/news/index.html","id":"rmcorr-043","dir":"Changelog","previous_headings":"","what":"rmcorr 0.4.3","title":"rmcorr 0.4.3","text":"CRAN release: 2021-04-01 Updated vignette","code":""},{"path":"http://lmarusich.github.io/rmcorr/news/index.html","id":"rmcorr-042","dir":"Changelog","previous_headings":"","what":"rmcorr 0.4.2","title":"rmcorr 0.4.2","text":"CRAN release: 2021-03-30 Fixed another error bootstrapped confidence intervals Updated vignette","code":""},{"path":"http://lmarusich.github.io/rmcorr/news/index.html","id":"rmcorr-041","dir":"Changelog","previous_headings":"","what":"rmcorr 0.4.1","title":"rmcorr 0.4.1","text":"CRAN release: 2020-08-26 Fixed error last update bootstrapped confidence intervals","code":""},{"path":"http://lmarusich.github.io/rmcorr/news/index.html","id":"rmcorr-040","dir":"Changelog","previous_headings":"","what":"rmcorr 0.4.0","title":"rmcorr 0.4.0","text":"CRAN release: 2020-06-27 Added argument confidence level Reset contrast option running rmcorr Added parent.frame access","code":""},{"path":"http://lmarusich.github.io/rmcorr/news/index.html","id":"rmcorr-030","dir":"Changelog","previous_headings":"","what":"rmcorr 0.3.0","title":"rmcorr 0.3.0","text":"CRAN release: 2018-02-28 column names can entered strings dynamically dataset parameter longer required plot.rmc function Added NEWS.md file track changes package.","code":""}]
